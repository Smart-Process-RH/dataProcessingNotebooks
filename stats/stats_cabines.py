# ============================================================
# SCRIPT:   Cabine Analytics - API Integration
# Description: Analyser les donn√©es de la Cabine (CV cr√©√©s, imprim√©s, offres consult√©es)
# Repository:   Zaidoudou/dataProcessingNotebooks
# Branch:  statysics-by-vlad
# ============================================================
# Imports

import sys
print("üîÑ D√©marrage du script...", file=sys.stderr)
print("üì¶ V√©rification des imports...", file=sys.stderr)

try:
    import requests
    print("‚úì requests import√©", file=sys.stderr)
except ImportError as e:
    print(f"‚ùå Erreur import requests: {e}", file=sys.stderr)
    sys.exit(1)

try:
    import pandas as pd
    print("‚úì pandas import√©", file=sys.stderr)
except ImportError as e:
    print(f"‚ùå Erreur import pandas: {e}", file=sys.stderr)
    sys.exit(1)

import warnings
import os
import time

print("‚úì Tous les imports sont OK\n", file=sys.stderr)

warnings.filterwarnings('ignore')

# ============================================================
# ‚öôÔ∏è CONFIGURATION - MODIFIEZ ICI
# ============================================================

# üìÖ DATES PRINCIPALES
DATE_START = "2025-09-01"           # ‚Üê DATE DE D√âBUT (YYYY-MM-DD)
DATE_END = "2026-01-19"             # ‚Üê DATE DE FIN (YYYY-MM-DD)

# üè¢ S√âLECTION DES CABINES √Ä ANALYSER
# Options:
#   "all"  ‚Üí Analyser toutes les cabines
#   "NAME" ‚Üí Analyser une cabine sp√©cifique (ex: "Cabine 1", "Cabine 2", etc)
CABINES_TO_ANALYZE = "all"          # ‚Üê MODIFIEZ: "all" ou nom de cabine sp√©cifique

# üìÖ ANALYSE PAR SEMAINE ET PAR JOUR
# Options:
#   ""          ‚Üí Analyser TOUTES les semaines et tous les jours
#   "YYYY-MM"   ‚Üí Analyser seulement le mois sp√©cifi√© (ex: "2026-01")
#   "YYYY-MM-DD" ‚Üí Analyser un jour sp√©cifique
ANALYZE_PERIOD = "2026-01"                 # ‚Üê MODIFIEZ: "" (tout), "2026-01" (mois), ou "2026-01-15" (jour)

# üìä OPTIONS D'AFFICHAGE
SHOW_DETAILS = True                 # ‚Üê Afficher d√©tails (toujours actif)
EXPORT_TO_EXCEL = False             # ‚Üê G√©n√©rer fichier Excel (d√©sactiv√©)

# üåç ENVIRONNEMENT
ENVIRONMENT = 'PRODUCTION'          # ‚Üê MODIFIEZ: 'STAGING' ou 'PRODUCTION'

# ============================================================
# üìä INFORMATIONS DE CONFIGURATION
# ============================================================
#
# CABINES_TO_ANALYZE:
#   - "all"    : Affiche toutes les cabines avec toutes les √©tapes
#   - "NAME"   : Affiche seulement la cabine sp√©cifi√©e
#
# ANALYZE_PERIOD (pour semaines et jours):
#   - ""       : Affiche TOP 5 des mois entiers + TOP 5 semaines + TOP 5 jours
#   - "2026-01": Affiche seulement le mois de janvier 2026
#   - "2026-01-15": Affiche seulement le jour 15 janvier 2026
#
# Les √©tapes affich√©es pour chaque cabine:
# - √âtape 3: Filtrage et enrichissement
# - √âtape 3.5: S√©lection clients
# - √âtape 4: Statistiques globales
# - √âtape 5: Statistiques par p√©riode
# - √âtape 6: Statistiques par mois (d√©taill√©es)
# - √âtape 7: Top Clients
# - √âtape 8: R√©partition par statut
# - √âtape 9: Top Campagnes
# - √âtape 10: Export Excel
# - √âtape 11: Analyse par semaine
# - √âtape 12: Analyse par jour

# ============================================================
# CONFIGURATION DE L'API - NE MODIFIEZ PAS
# ============================================================

# URLs et cl√©s API
API_STAGING_URL = 'https://cibli-api.agency.lonestone.io/api'
API_STAGING_KEY = 'PGZ4qtc5jtf@rph3twf'

API_PROD_URL = 'https://app-api.ciblijob.fr/api'
API_PROD_KEY = 'txf.hpc9aut9rbd2KWA'

# S√©lectionner l'URL et la cl√© selon l'environnement
if ENVIRONMENT == 'STAGING':
    API_URL = API_STAGING_URL
    API_KEY = API_STAGING_KEY
    ENV_STATUS = 'üß™ STAGING (Environnement de test)'
else:
    API_URL = API_PROD_URL
    API_KEY = API_PROD_KEY
    ENV_STATUS = 'üöÄ PRODUCTION'

# Cr√©er le dossier d'exports s'il n'existe pas
if not os.path.exists('exports'):
    os.makedirs('exports')

# Headers pour les requ√™tes API
HEADERS = {
    'x-secret-key': API_KEY
}

# Afficher la configuration
print('‚úÖ Configuration charg√©e :  ')
print(f'   Environnement:       {ENV_STATUS}')
print(f'   URL API:             {API_URL}')
print(f'   P√©riode:             {DATE_START} √† {DATE_END}')
print(f'   Cabines √† analyser:  {CABINES_TO_ANALYZE}')
print(f'   P√©riode d√©tails:     {ANALYZE_PERIOD if ANALYZE_PERIOD else "TOUTES les p√©riodes"}')
print()
print('üí° Astuce:   Pour changer les param√®tres, modifiez les variables ci-dessus.')

# ============================================================
# üì• √âTAPE 1 : R√©cup√©ration des donn√©es API
# ============================================================

print('\nüì• R√©cup√©ration des donn√©es depuis l\'API...')
print('=' * 60)

# Fonction utilitaire pour afficher l'√©tat de l'API
def get_status_icon(status_code):
    if 200 <= status_code < 300:
        return '‚úÖ'
    elif 400 <= status_code < 500:
        return '‚ö†Ô∏è'
    else:
        return '‚ùå'

def get_status_text(status_code):
    status_map = {
        200: 'OK',
        201: 'Created',
        204: 'No Content',
        400: 'Bad Request',
        401: 'Unauthorized',
        403: 'Forbidden',
        404: 'Not Found',
        500: 'Internal Server Error',
        502: 'Bad Gateway',
        503: 'Service Unavailable'
    }
    return status_map.get(status_code, 'Unknown')

# 1Ô∏è‚É£ R√©cup√©rer les cabines (booths)
print('\n1Ô∏è‚É£ R√©cup√©ration des cabines...')
try:
    start_time = time.time()
    print(f'   üì° URL: {API_URL}/booths/all')
    print(f'   üîë Headers: {{"x-secret-key": "***"}}')
    response_booths = requests.get(
        f'{API_URL}/booths/all',
        headers=HEADERS,
        timeout=10
    )
    elapsed_time = time.time() - start_time
    status_icon = get_status_icon(response_booths.status_code)
    status_text = get_status_text(response_booths.status_code)
    print(f'   √âtat API: {status_icon} {response_booths.status_code} {status_text} ({elapsed_time:.2f}s)')
    print(f'   üìù Taille r√©ponse: {len(response_booths.text)} bytes')
    print(f'   üì¶ Contenu brut:\n{response_booths.text[:500]}\n')
    if response_booths.status_code == 200:
        booths_data = response_booths.json()
        print(f'   ‚úì JSON valide')
        print(f'   ‚úì Type: {type(booths_data).__name__}')
        if isinstance(booths_data, list):
            booths_df = pd.DataFrame(booths_data)
            print(f'‚úÖ {len(booths_df)} cabines r√©cup√©r√©es')
        elif isinstance(booths_data, dict):
            booths_df = pd.DataFrame([booths_data])
            print(f'‚úÖ Donn√©es cabine re√ßues')
        else:
            print(f'‚ö†Ô∏è Format de r√©ponse inattendu: {type(booths_data)}')
            booths_df = pd.DataFrame()
    else:
        print(f'‚ùå Erreur HTTP: {response_booths.status_code}')
        print(f'   üìù R√©ponse compl√®te: {response_booths.text[:500]}')
        booths_df = pd.DataFrame()
except Exception as e:
    print(f'‚ùå Exception: {str(e)}')
    import traceback
    traceback.print_exc()
    booths_df = pd.DataFrame()

# 2Ô∏è‚É£ R√©cup√©rer les √©v√©nements
print('\n2Ô∏è‚É£ R√©cup√©ration des √©v√©nements...')
try:
    start_time = time.time()
    print(f'   üì° URL: {API_URL}/analytics/events')
    print(f'   üìÖ Param√®tres: from={DATE_START}, to={DATE_END}')
    response_events = requests.get(
        f'{API_URL}/analytics/events',
        headers=HEADERS,
        params={'from': DATE_START, 'to': DATE_END},
        timeout=10
    )
    elapsed_time = time.time() - start_time
    status_icon = get_status_icon(response_events.status_code)
    status_text = get_status_text(response_events.status_code)
    print(f'   √âtat API: {status_icon} {response_events.status_code} {status_text} ({elapsed_time:.2f}s)')
    print(f'   üìù Taille r√©ponse: {len(response_events.text)} bytes')
    print(f'   üì¶ Contenu brut:\n{response_events.text[:500]}\n')
    if response_events.status_code == 200:
        events_data = response_events.json()
        print(f'   ‚úì JSON valide')
        print(f'   ‚úì Type: {type(events_data).__name__}')
        if isinstance(events_data, list):
            events_df = pd.DataFrame(events_data)
            print(f'‚úÖ {len(events_df)} √©v√©nements r√©cup√©r√©s')
        elif isinstance(events_data, dict):
            events_df = pd.DataFrame([events_data])
            print(f'‚úÖ Donn√©es √©v√©nement re√ßues')
        else:
            print(f'‚ö†Ô∏è Format de r√©ponse inattendu: {type(events_data)}')
            events_df = pd.DataFrame()
    else:
        print(f'‚ùå Erreur HTTP: {response_events.status_code}')
        print(f'   üìù R√©ponse compl√®te: {response_events.text[:500]}')
        events_df = pd.DataFrame()
except Exception as e:
    print(f'‚ùå Exception: {str(e)}')
    import traceback
    traceback.print_exc()
    events_df = pd.DataFrame()

# 3Ô∏è‚É£ R√©cup√©rer les KPIs
print('\n3Ô∏è‚É£ R√©cup√©ration des KPIs...')
try:
    start_time = time.time()
    print(f'   üì° URL: {API_URL}/analytics/kpis')
    print(f'   üìÖ Param√®tres: from={DATE_START}, to={DATE_END}')
    response_kpis = requests.get(
        f'{API_URL}/analytics/kpis',
        headers=HEADERS,
        params={'from': DATE_START, 'to': DATE_END},
        timeout=10
    )
    elapsed_time = time.time() - start_time
    status_icon = get_status_icon(response_kpis.status_code)
    status_text = get_status_text(response_kpis.status_code)
    print(f'   √âtat API: {status_icon} {response_kpis.status_code} {status_text} ({elapsed_time:.2f}s)')
    print(f'   üìù Taille r√©ponse: {len(response_kpis.text)} bytes')
    print(f'   üì¶ Contenu brut:\n{response_kpis.text[:500]}\n')
    if response_kpis.status_code == 200:
        kpis_data = response_kpis.json()
        print(f'   ‚úì JSON valide')
        print(f'   ‚úì Type: {type(kpis_data).__name__}')
        kpis_df = pd.DataFrame([kpis_data] if isinstance(kpis_data, dict) else kpis_data)
        print(f'‚úÖ KPIs r√©cup√©r√©s')
    else:
        print(f'‚ùå Erreur HTTP: {response_kpis.status_code}')
        print(f'   üìù R√©ponse compl√®te: {response_kpis.text[:500]}')
        kpis_df = pd.DataFrame()
except Exception as e:
    print(f'‚ùå Exception: {str(e)}')
    import traceback
    traceback.print_exc()
    kpis_df = pd.DataFrame()

# 4Ô∏è‚É£ R√©cup√©rer la timeline
print('\n4Ô∏è‚É£ R√©cup√©ration de la timeline...')
try:
    start_time = time.time()
    print(f'   üì° URL: {API_URL}/analytics/timeline')
    print(f'   üìÖ Param√®tres: from={DATE_START}, to={DATE_END}')
    response_timeline = requests.get(
        f'{API_URL}/analytics/timeline',
        headers=HEADERS,
        params={'from': DATE_START, 'to': DATE_END},
        timeout=10
    )
    elapsed_time = time.time() - start_time
    status_icon = get_status_icon(response_timeline.status_code)
    status_text = get_status_text(response_timeline.status_code)
    print(f'   √âtat API: {status_icon} {response_timeline.status_code} {status_text} ({elapsed_time:.2f}s)')
    print(f'   üìù Taille r√©ponse: {len(response_timeline.text)} bytes')
    print(f'   üì¶ Contenu brut:\n{response_timeline.text[:500]}\n')
    if response_timeline.status_code == 200:
        timeline_data = response_timeline.json()
        print(f'   ‚úì JSON valide')
        print(f'   ‚úì Type: {type(timeline_data).__name__}')
        timeline_df = pd.DataFrame(timeline_data)
        print(f'‚úÖ Timeline r√©cup√©r√©e')
    else:
        print(f'‚ùå Erreur HTTP: {response_timeline.status_code}')
        print(f'   üìù R√©ponse compl√®te: {response_timeline.text[:500]}')
        timeline_df = pd.DataFrame()
except Exception as e:
    print(f'‚ùå Exception: {str(e)}')
    import traceback
    traceback.print_exc()
    timeline_df = pd.DataFrame()

# 5Ô∏è‚É£ R√©cup√©rer les sessions
print('\n5Ô∏è‚É£ R√©cup√©ration des sessions...')
try:
    start_time = time.time()
    print(f'   üì° URL: {API_URL}/analytics/sessions')
    print(f'   üìÖ Param√®tres: from={DATE_START}, to={DATE_END}')
    response_sessions = requests.get(
        f'{API_URL}/analytics/sessions',
        headers=HEADERS,
        params={'from': DATE_START, 'to': DATE_END},
        timeout=10
    )
    elapsed_time = time.time() - start_time
    status_icon = get_status_icon(response_sessions.status_code)
    status_text = get_status_text(response_sessions.status_code)
    print(f'   √âtat API: {status_icon} {response_sessions.status_code} {status_text} ({elapsed_time:.2f}s)')
    print(f'   üìù Taille r√©ponse: {len(response_sessions.text)} bytes')
    print(f'   üì¶ Contenu brut:\n{response_sessions.text[:500]}\n')
    if response_sessions.status_code == 200:
        sessions_data = response_sessions.json()
        print(f'   ‚úì JSON valide')
        print(f'   ‚úì Type: {type(sessions_data).__name__}')
        # Extraire la liste 'sessions' si c'est un dict avec cl√© 'sessions'
        if isinstance(sessions_data, dict) and 'sessions' in sessions_data:
            sessions_data = sessions_data['sessions']
            print(f'   ‚úì Extracting "sessions" list from dict')
        if isinstance(sessions_data, list):
            sessions_df = pd.DataFrame(sessions_data)
            print(f'‚úÖ {len(sessions_df)} sessions r√©cup√©r√©es')
        elif isinstance(sessions_data, dict):
            sessions_df = pd.DataFrame([sessions_data])
            print(f'‚úÖ Donn√©es session re√ßues')
        else:
            print(f'‚ö†Ô∏è Format de r√©ponse inattendu: {type(sessions_data)}')
            sessions_df = pd.DataFrame()
    else:
        print(f'‚ùå Erreur HTTP: {response_sessions.status_code}')
        print(f'   üìù R√©ponse compl√®te: {response_sessions.text[:500]}')
        sessions_df = pd.DataFrame()
except Exception as e:
    print(f'‚ùå Exception: {str(e)}')
    import traceback
    traceback.print_exc()
    sessions_df = pd.DataFrame()

# 6Ô∏è‚É£ R√©cup√©rer les interviews par jour
print('\n6Ô∏è‚É£ R√©cup√©ration des interviews par jour...')
try:
    start_time = time.time()
    print(f'   üì° URL: {API_URL}/interviews/analytics/per-day')
    print(f'   üìÖ Param√®tres: from={DATE_START}, to={DATE_END}')
    response_interviews = requests.get(
        f'{API_URL}/interviews/analytics/per-day',
        headers=HEADERS,
        params={'from': DATE_START, 'to': DATE_END},
        timeout=10
    )
    elapsed_time = time.time() - start_time
    status_icon = get_status_icon(response_interviews.status_code)
    status_text = get_status_text(response_interviews.status_code)
    print(f'   √âtat API: {status_icon} {response_interviews.status_code} {status_text} ({elapsed_time:.2f}s)')
    print(f'   üìù Taille r√©ponse: {len(response_interviews.text)} bytes')
    print(f'   üì¶ Contenu brut:\n{response_interviews.text[:500]}\n')
    if response_interviews.status_code == 200:
        interviews_data = response_interviews.json()
        print(f'   ‚úì JSON valide')
        print(f'   ‚úì Type: {type(interviews_data).__name__}')
        if isinstance(interviews_data, list):
            interviews_df = pd.DataFrame(interviews_data)
            print(f'‚úÖ Interviews par jour r√©cup√©r√©s')
        elif isinstance(interviews_data, dict):
            interviews_df = pd.DataFrame([interviews_data])
            print(f'‚úÖ Donn√©es interview re√ßues')
        else:
            print(f'‚ö†Ô∏è Format de r√©ponse inattendu: {type(interviews_data)}')
            interviews_df = pd.DataFrame()
    else:
        print(f'‚ùå Erreur HTTP: {response_interviews.status_code}')
        print(f'   üìù R√©ponse compl√®te: {response_interviews.text[:500]}')
        interviews_df = pd.DataFrame()
except Exception as e:
    print(f'‚ùå Exception: {str(e)}')
    import traceback
    traceback.print_exc()
    interviews_df = pd.DataFrame()

# 7Ô∏è‚É£ R√©cup√©rer les jobs
print('\n7Ô∏è‚É£ R√©cup√©ration des jobs...')
try:
    start_time = time.time()
    print(f'   üì° URL: {API_URL}/jobs')
    response_jobs = requests.get(
        f'{API_URL}/jobs',
        headers=HEADERS,
        timeout=10
    )
    elapsed_time = time.time() - start_time
    status_icon = get_status_icon(response_jobs.status_code)
    status_text = get_status_text(response_jobs.status_code)
    print(f'   √âtat API: {status_icon} {response_jobs.status_code} {status_text} ({elapsed_time:.2f}s)')
    if response_jobs.status_code == 200:
        jobs_data = response_jobs.json()
        if isinstance(jobs_data, list):
            jobs_df = pd.DataFrame(jobs_data)
            print(f'‚úÖ {len(jobs_df)} jobs r√©cup√©r√©s')
        elif isinstance(jobs_data, dict) and 'data' in jobs_data:
            jobs_df = pd.DataFrame(jobs_data['data'])
            print(f'‚úÖ {len(jobs_df)} jobs r√©cup√©r√©s')
        else:
            print(f'‚ö†Ô∏è Format inattendu')
            jobs_df = pd.DataFrame()
    else:
        print(f'‚ùå Erreur HTTP: {response_jobs.status_code}')
        jobs_df = pd.DataFrame()
except Exception as e:
    print(f'‚ùå Exception: {str(e)}')
    jobs_df = pd.DataFrame()

# 8Ô∏è‚É£ R√©cup√©rer les organizations
print('\n8Ô∏è‚É£ R√©cup√©ration des organizations...')
try:
    start_time = time.time()
    print(f'   üì° URL: {API_URL}/organizations')
    response_orgs = requests.get(
        f'{API_URL}/organizations',
        headers=HEADERS,
        timeout=10
    )
    elapsed_time = time.time() - start_time
    status_icon = get_status_icon(response_orgs.status_code)
    status_text = get_status_text(response_orgs.status_code)
    print(f'   √âtat API: {status_icon} {response_orgs.status_code} {status_text} ({elapsed_time:.2f}s)')
    if response_orgs.status_code == 200:
        orgs_data = response_orgs.json()
        if isinstance(orgs_data, list):
            organizations_df = pd.DataFrame(orgs_data)
            print(f'‚úÖ {len(organizations_df)} organizations r√©cup√©r√©es')
        elif isinstance(orgs_data, dict) and 'data' in orgs_data:
            organizations_df = pd.DataFrame(orgs_data['data'])
            print(f'‚úÖ {len(organizations_df)} organizations r√©cup√©r√©es')
        else:
            print(f'‚ö†Ô∏è Format inattendu')
            organizations_df = pd.DataFrame()
    else:
        print(f'‚ùå Erreur HTTP: {response_orgs.status_code}')
        organizations_df = pd.DataFrame()
except Exception as e:
    print(f'‚ùå Exception: {str(e)}')
    organizations_df = pd.DataFrame()

print('\n' + '=' * 60)
print('‚úÖ Toutes les donn√©es ont √©t√© r√©cup√©r√©es avec succ√®s !')

# ============================================================
# üîç √âTAPE 2 : Filtrage et enrichissement
# ============================================================

print('\nüîç Filtrage et enrichissement des donn√©es...')
print('=' * 60)

# Convertir les dates
if not events_df.empty and 'created_at' in events_df.columns:
    events_df['created_at'] = pd.to_datetime(events_df['created_at'], errors='coerce')

if not timeline_df.empty and 'date' in timeline_df.columns:
    timeline_df['date'] = pd.to_datetime(timeline_df['date'], errors='coerce')

if not interviews_df.empty and 'date' in interviews_df.columns:
    interviews_df['date'] = pd.to_datetime(interviews_df['date'], errors='coerce')

print('‚úÖ Dates converties')

# Afficher la structure des donn√©es re√ßues (D√âBOGAGE)
print('\nüîç D√âBOGAGE - Structure des donn√©es re√ßues:')
print('‚îÄ' * 60)
print(f'1Ô∏è‚É£ Events DataFrame:')
if not events_df.empty:
    print(f'   Colonnes: {list(events_df.columns)}')
    print(f'   Nombre de lignes: {len(events_df)}')
    print(f'   Premiers √©l√©ments:\n{events_df.head(2).to_string()}')
else:
    print(f'   ‚ö†Ô∏è DataFrame vide')

print(f'\n2Ô∏è‚É£ KPIs DataFrame:')
if not kpis_df.empty:
    print(f'   Colonnes: {list(kpis_df.columns)}')
    print(f'   Nombre de lignes: {len(kpis_df)}')
    print(f'   Contenu:\n{kpis_df.to_string()}')
else:
    print(f'   ‚ö†Ô∏è DataFrame vide')

print(f'\n3Ô∏è‚É£ Sessions DataFrame:')
if not sessions_df.empty:
    print(f'   Colonnes: {list(sessions_df.columns)}')
    print(f'   Nombre de lignes: {len(sessions_df)}')
else:
    print(f'   ‚ö†Ô∏è DataFrame vide')

print(f'\n4Ô∏è‚É£ Timeline DataFrame:')
if not timeline_df.empty:
    print(f'   Colonnes: {list(timeline_df.columns)}')
    print(f'   Nombre de lignes: {len(timeline_df)}')
else:
    print(f'   ‚ö†Ô∏è DataFrame vide')

print('\n' + '=' * 60)

# Cr√©er les mappings pour les cabines
if not booths_df.empty and 'id' in booths_df.columns:
    # Construire le mapping correctement
    booth_map = {}
    for idx, row in booths_df.iterrows():
        booth_id = row['id']
        # Chercher le nom dans cet ordre: 'label', 'name', 'title'
        booth_name = row.get('label') or row.get('name') or row.get('title') or f'Cabine {booth_id}'
        booth_map[booth_id] = str(booth_name).strip()  # Assurer que c'est un string propre
    print(f'‚úÖ {len(booth_map)} cabines mapp√©es')
    # Afficher le mapping pour diagnostique
    print(f'   Mapping des cabines:')
    for booth_id, booth_name in list(booth_map.items())[:5]:
        print(f'      {booth_id}: {booth_name}')
else:
    booth_map = {}
    print('‚ö†Ô∏è Aucune cabine trouv√©e')

# Cr√©er les mappings pour les jobs
job_map = {}
if not jobs_df.empty and 'id' in jobs_df.columns:
    for idx, row in jobs_df.iterrows():
        job_id = row['id']
        # Chercher le titre dans cet ordre: 'title', 'name', 'label'
        job_title = row.get('title') or row.get('name') or row.get('label') or f'Job {job_id}'
        job_map[job_id] = str(job_title).strip()
    print(f'‚úÖ {len(job_map)} jobs mapp√©s')
    print(f'   Mapping des jobs:')
    for job_id, job_title in list(job_map.items())[:5]:
        print(f'      {job_id}: {job_title}')

# Cr√©er les mappings pour les organizations
org_map = {}
if not organizations_df.empty and 'id' in organizations_df.columns:
    for idx, row in organizations_df.iterrows():
        org_id = row['id']
        # Chercher le nom dans cet ordre: 'name', 'title', 'label'
        org_name = row.get('name') or row.get('title') or row.get('label') or f'Org {org_id}'
        org_map[org_id] = str(org_name).strip()
    print(f'‚úÖ {len(org_map)} organizations mapp√©es')
    print(f'   Mapping des organizations:')
    for org_id, org_name in list(org_map.items())[:5]:
        print(f'      {org_id}: {org_name}')

print('\n' + '=' * 60)
print('‚úÖ Filtrage et enrichissement termin√©s !')

# ============================================================
# üè¢ CABINES DISPONIBLES
# ============================================================

print('\n' + '=' * 100)
print('üè¢ CABINES DISPONIBLES')
print('=' * 100)

if booth_map:
    print(f'\nüìç Total de cabines disponibles: {len(booth_map)}')
    print(f'\n   {"Rang":<6} {"ID Cabine":<40} {"Nom de la Cabine":<50}')
    print('   ' + '‚îÄ' * 102)
    for idx, (booth_id, booth_name) in enumerate(sorted(booth_map.items(), key=lambda x: x[1]), 1):
        print(f'   {idx:<6} {str(booth_id):<40} {booth_name:<50}')
    print('   ' + '‚îÄ' * 102)
    print(f'\nüí° Pour analyser une cabine sp√©cifique, modifiez CABINES_TO_ANALYZE dans la configuration')
    print(f'   Exemples: "Cabine 1", "Paris", "{list(booth_map.values())[0] if booth_map else "Nom"}"')
else:
    print('\n‚ö†Ô∏è Aucune cabine disponible')

# ============================================================
# üìä √âTAPE 3 : Filtrage et enrichissement + √âTAPE 3.5 : S√©lection clients
# ============================================================

print('\n' + '=' * 60)
print('üîç FILTRAGE ET ENRICHISSEMENT')
print('=' * 60)

# Afficher les candidatures filtr√©es par source
print(f'\nüì• Candidatures filtr√©es par source:')
if not events_df.empty and 'source' in events_df.columns:
    source_counts = events_df['source'].value_counts()
    for source, count in source_counts.items():
        print(f'   {source}: {count}')
else:
    print('   ‚ÑπÔ∏è Donn√©es non disponibles')

# Afficher les candidatures dans la p√©riode date
print(f'\nüìÖ Candidatures dans la p√©riode {DATE_START} √† {DATE_END}:')
if not events_df.empty and 'created_at' in events_df.columns:
    period_count = len(events_df)
    print(f'   Total: {period_count}')
else:
    print('   ‚ÑπÔ∏è Donn√©es non disponibles')

print(f'\nüìä Nombre total de clients disponibles: {len(booth_map)}')
print(f'Cabines mapp√©es: {len(booth_map)}')

# ============================================================
# üìä √âTAPE 4 : Statistiques globales
# ============================================================

print('\n' + '=' * 60)
print(f'{ENV_STATUS}')
print('\n' + '=' * 60)
print(f'{ENV_STATUS}')
print('=' * 60)

# Initialiser les m√©triques
total_cv_created = 0
total_cv_printed = 0
total_job_offers_viewed = 0
total_sessions = 0
total_events = 0
total_applications = 0
total_users_completed_session = 0

print(f'\nüìä Statistiques globales de la p√©riode {DATE_START} √† {DATE_END}:')
print('‚îÄ' * 60)
if not kpis_df.empty:
    print('üìà Source: KPIs API')
    kpis_row = kpis_df.iloc[0] if len(kpis_df) > 0 else {}

    print(f'   Colonnes disponibles: {list(kpis_df.columns)}')

    # Les vrais noms de colonnes de l'API
    if 'sessionCount' in kpis_df.columns:
        total_sessions = int(kpis_row['sessionCount'])
        print(f'   ‚úì Sessions trouv√©: sessionCount = {total_sessions}')

    if 'interviewsEnded' in kpis_df.columns:
        total_users_completed_session = int(kpis_row['interviewsEnded'])
        print(f'   ‚úì Interviews compl√©t√©es trouv√©: interviewsEnded = {total_users_completed_session}')

    if 'totalApplications' in kpis_df.columns:
        total_applications = int(kpis_row['totalApplications'])
        print(f'   ‚úì Candidatures trouv√©: totalApplications = {total_applications}')

    if 'uniqueUsersViewedJobs' in kpis_df.columns:
        total_job_offers_viewed = int(kpis_row['uniqueUsersViewedJobs'])
        print(f'   ‚úì Offres consult√©es trouv√©: uniqueUsersViewedJobs = {total_job_offers_viewed}')

    if 'totalPrints' in kpis_df.columns:
        total_cv_printed = int(kpis_row['totalPrints'])
        print(f'   ‚úì CV imprim√©s trouv√©: totalPrints = {total_cv_printed}')

    if 'uniqueUsersWithCvDownload' in kpis_df.columns:
        total_cv_created = int(kpis_row['uniqueUsersWithCvDownload'])
        print(f'   ‚úì CV t√©l√©charg√©s trouv√©: uniqueUsersWithCvDownload = {total_cv_created}')

    # Afficher le contenu complet pour diagnostique
    print(f'\n   üìã Contenu complet des KPIs:')
    for col in kpis_df.columns:
        val = kpis_row[col]
        if isinstance(val, dict):
            print(f'      {col}: {val}')
        else:
            print(f'      {col}: {val}')

# Strat√©gie 2: Essayer depuis les √©v√©nements si KPIs vide
elif not events_df.empty:
    print('üìà Source: Events API')
    if 'event_type' in events_df.columns:
        event_counts = events_df['event_type'].value_counts()
        print(f'   Types d\'√©v√©nements trouv√©s: {event_counts.to_dict()}')
        total_cv_created = event_counts.get('CV_CREATED', 0)
        total_cv_printed = event_counts.get('CV_PRINTED', 0)
        total_job_offers_viewed = event_counts.get('JOB_OFFER_VIEWED', 0)
        total_applications = event_counts.get('APPLICATION_SUBMITTED', 0)
    total_events = len(events_df)

# Strat√©gie 3: Essayer depuis la timeline
elif not timeline_df.empty:
    print('üìà Source: Timeline API')
    if len(timeline_df) > 0:
        last_day = timeline_df.iloc[-1]
        cv_cols = ['cv_created', 'cvCreated', 'total_cv_created']
        for col in cv_cols:
            if col in timeline_df.columns:
                total_cv_created = timeline_df[col].sum()
                break

        print(f'   Donn√©es r√©cup√©r√©es de la timeline')

# Sessions
# Ne pas utiliser len(sessions_df) car c'est souvent une seule ligne contenant toutes les sessions
# Utiliser sessionCount des KPIs qui a d√©j√† √©t√© extrait
if total_sessions == 0 and not sessions_df.empty:
    # Fallback: si sessionCount n'a pas √©t√© trouv√© dans KPIs
    total_sessions = len(sessions_df)
    print(f'üìà Sessions trouv√©es (fallback): {total_sessions}')
else:
    if total_sessions > 0:
        print(f'üìà Sessions trouv√©es: {total_sessions}')

# Afficher les r√©sultats TOUJOURS
print(f'\n‚úÖ R√âSULTATS FINAUX:')
print('‚îÄ' * 60)
print(f'üîµ Nombre total de CV cr√©√©s: {total_cv_created}')
print(f'üü¢ Nombre total de CV imprim√©s: {total_cv_printed}')
print(f'üü° Nombre d\'offres consult√©es: {total_job_offers_viewed}')
print(f'üü† Nombre de candidatures: {total_applications}')
print(f'üî¥ Nombre de sessions: {total_sessions}')
print(f'üü£ Nombre d\'utilisateurs ayant compl√©t√© une session: {total_users_completed_session}')

# Statistiques suppl√©mentaires
if total_cv_created > 0:
    print(f'\nüìä Statistiques suppl√©mentaires:')
    if total_cv_printed > 0:
        print(f'   - Taux d\'impression: {(total_cv_printed/total_cv_created)*100:.1f}%')
    if total_job_offers_viewed > 0:
        print(f'   - Ratio offres/CV: {(total_job_offers_viewed/total_cv_created):.2f}')
    if total_applications > 0:
        print(f'   - Ratio candidatures/CV: {(total_applications/total_cv_created):.2f}')
    if total_sessions > 0:
        print(f'   - Ratio CV/session: {(total_cv_created/total_sessions):.2f}')
        if total_users_completed_session > 0:
            print(f'   - Taux de compl√©tion de session: {(total_users_completed_session/total_sessions)*100:.1f}%')

# ============================================================
# üìÖ √âTAPE 5 : Statistiques par p√©riode (Global)
# ============================================================

print('\nüìÖ √âTAPE 5 : Statistiques par p√©riode')
print('‚îÄ' * 60)
print('\n‚úÖ Confirmation de sauvegarde des fichiers mensuels: N/A (export Excel d√©sactiv√©)')

if not sessions_df.empty and 'startedAt' in sessions_df.columns:
    sessions_df['startedAt'] = pd.to_datetime(sessions_df['startedAt'], errors='coerce')
    sessions_df['year_month'] = sessions_df['startedAt'].dt.to_period('M')

    print(f'\nüìä Nombre de candidatures par mois:')
    monthly_total = sessions_df.groupby('year_month').size()
    for month, count in monthly_total.items():
        print(f'   {month}: {count}')
else:
    print(f'\n   ‚ÑπÔ∏è Donn√©es non disponibles')

# ============================================================
# üè¢ ANALYSE PAR CABINE
# ============================================================

print('\n' + '=' * 60)
print('üè¢ ANALYSE PAR CABINE')
print('=' * 60)

# Boucle principale: traiter chaque cabine
if not sessions_df.empty and 'boothId' in sessions_df.columns:
    # Pr√©parer les donn√©es de sessions
    sessions_df['startedAt'] = pd.to_datetime(sessions_df['startedAt'], errors='coerce')
    sessions_df['date'] = sessions_df['startedAt'].dt.date
    sessions_df['year_month'] = sessions_df['startedAt'].dt.to_period('M')
    sessions_df['year_week'] = sessions_df['startedAt'].dt.isocalendar().week
    sessions_df['year'] = sessions_df['startedAt'].dt.isocalendar().year

    # Obtenir les cabines uniques tri√©es
    booth_ids = sorted(sessions_df['boothId'].dropna().unique())

    # Filtrer les cabines selon CABINES_TO_ANALYZE
    if CABINES_TO_ANALYZE != "all":
        # Chercher la cabine sp√©cifi√©e
        matching_booths = []
        for booth_id in booth_ids:
            if booth_id in booth_map:
                booth_name = booth_map[booth_id]
            else:
                booth_name = f'Cabine {str(booth_id)[:8]}...'

            # V√©rifier si le nom contient la cha√Æne demand√©e (case-insensitive)
            if CABINES_TO_ANALYZE.lower() in booth_name.lower():
                matching_booths.append(booth_id)

        if matching_booths:
            booth_ids = matching_booths
            print(f'\n‚úÖ Cabine(s) s√©lectionn√©e(s): {CABINES_TO_ANALYZE}')
        else:
            print(f'\n‚ö†Ô∏è Aucune cabine trouv√©e correspondant √†: {CABINES_TO_ANALYZE}')
            print(f'   Cabines disponibles:')
            for booth_id in sorted(sessions_df['boothId'].dropna().unique()):
                if booth_id in booth_map:
                    print(f'      - {booth_map[booth_id]}')

    # Initialiser la liste pour stocker les donn√©es r√©capitulatives
    cabines_recap = []

    for booth_idx, booth_id in enumerate(booth_ids, 1):
        # Obtenir le nom de la cabine
        if booth_id in booth_map:
            booth_name = booth_map[booth_id]
        else:
            booth_name = f'Cabine {str(booth_id)[:8]}...'

        # Filtrer les sessions pour cette cabine
        booth_sessions = sessions_df[sessions_df['boothId'] == booth_id]

        if len(booth_sessions) == 0:
            continue

        print(f'\n\n{"=" * 100}')
        print(f'üè¢ {booth_name}')
        print(f'{"=" * 100}')

        # Statistiques globales pour cette cabine
        booth_cv_created = int(booth_sessions['hasCvDownloaded'].sum()) if 'hasCvDownloaded' in booth_sessions.columns else 0
        booth_cv_printed = int(booth_sessions['hasCvPrinted'].sum()) if 'hasCvPrinted' in booth_sessions.columns else 0
        booth_apps = int(booth_sessions['applicationsCount'].sum()) if 'applicationsCount' in booth_sessions.columns else 0
        booth_total_sessions = len(booth_sessions)

        print(f'\nüìä Statistiques Globales')
        print('‚îÄ' * 100)
        print(f'   CV cr√©√©s: {booth_cv_created}')
        print(f'   CV imprim√©s: {booth_cv_printed}')
        print(f'   Candidatures: {booth_apps}')
        print(f'   Sessions: {booth_total_sessions}')
        print(f'   P√©riode: {DATE_START} √† {DATE_END}')

        # Statistiques par mois
        print(f'\nüìÖ Candidatures par Mois')
        print('‚îÄ' * 100)
        print(f'   {"Mois":<15} {"Candidatures":>15}')
        print('   ' + '‚îÄ' * 96)
        monthly_stats = booth_sessions.groupby('year_month').size()
        for month, count in monthly_stats.items():
            print(f'   {str(month):<15} {count:>15}')

        # R√©partition par statut
        print(f'\nüìä R√©partition par Statut')
        print('‚îÄ' * 100)
        status_recap = {}
        if 'status' in booth_sessions.columns:
            status_counts = booth_sessions['status'].value_counts()
            total_status = status_counts.sum()
            for status, count in status_counts.items():
                percentage = (count / total_status * 100) if total_status > 0 else 0
                status_recap[status] = count
                print(f'   {status}: {count} ({percentage:.1f}%)')
        else:
            print(f'   ‚ÑπÔ∏è Donn√©es de statut non disponibles')

        # D√©tail des candidatures avec clients et campagnes
        print(f'\nüìã D√©tail des Candidatures (Client + Campagne)')
        print('‚îÄ' * 100)

        # Chercher les colonnes disponibles
        client_col = None
        job_col = None

        if 'clientId' in booth_sessions.columns:
            client_col = 'clientId'
        elif 'client_id' in booth_sessions.columns:
            client_col = 'client_id'

        if 'jobId' in booth_sessions.columns:
            job_col = 'jobId'
        elif 'job_id' in booth_sessions.columns:
            job_col = 'job_id'

        num_clients = 0
        num_campaigns = 0

        if client_col and job_col:
            # Cr√©er une table avec les candidatures group√©es par client et campagne
            print(f'   {"Client (Organisation)":<45} {"Campagne (Job)":<45} {"Candidatures":>15}')
            print('   ' + '‚îÄ' * 110)

            candidatures_detail = booth_sessions.groupby([client_col, job_col]).size().reset_index(name='count')
            candidatures_detail = candidatures_detail.sort_values('count', ascending=False)

            for _, row in candidatures_detail.iterrows():
                client_id = row[client_col]
                campaign_id = row[job_col]

                # Utiliser les mappings pour obtenir les noms
                client_name = org_map.get(client_id, str(client_id))[:43]
                campaign_name = job_map.get(campaign_id, str(campaign_id))[:43]

                count = int(row['count'])
                print(f'   {client_name:<45} {campaign_name:<45} {count:>15}')

            print('   ' + '‚îÄ' * 110)
            print(f'   Total: {len(candidatures_detail)} combinaisons client-campagne')
        elif client_col:
            print(f'   ‚ö†Ô∏è Donn√©es de campagnes non disponibles')
            print(f'   Affichage des clients uniquement:')
            client_counts = booth_sessions[client_col].value_counts()
            for client_id, count in client_counts.items():
                print(f'      {str(client_id):<40} : {count:>15} candidatures')
        elif job_col:
            print(f'   ‚ö†Ô∏è Donn√©es de clients non disponibles')
            print(f'   Affichage des campagnes uniquement:')
            job_counts = booth_sessions[job_col].value_counts()
            for job_id, count in job_counts.items():
                print(f'      {str(job_id):<40} : {count:>15} candidatures')
        else:
            print(f'   ‚ÑπÔ∏è Donn√©es de clients et campagnes non disponibles')

        # Liste compl√®te des clients (r√©capitulatif)
        print(f'\nüë• R√©capitulatif des Clients')
        print('‚îÄ' * 100)
        if client_col:
            client_counts = booth_sessions[client_col].value_counts()
            num_clients = len(client_counts)
            print(f'   {"Rang":<6} {"Client (Organisation)":<60} {"Candidatures":>15}')
            print('   ' + '‚îÄ' * 92)
            for idx, (client_id, count) in enumerate(client_counts.items(), 1):
                client_name = org_map.get(client_id, str(client_id))[:58]
                print(f'   {idx:<6} {client_name:<60} {count:>15}')
            print('   ' + '‚îÄ' * 92)
            print(f'   Total: {len(client_counts)} clients uniques')
        else:
            print(f'   ‚ÑπÔ∏è Donn√©es de clients non disponibles')

        # ===== ANALYSE D√âTAILL√âE PAR CLIENT =====
        print(f'\nüîç ANALYSE D√âTAILL√âE PAR CLIENT')
        print('‚îÄ' * 100)
        if client_col:
            clients_list = booth_sessions[client_col].unique()
            for client_id in clients_list:
                client_data = booth_sessions[booth_sessions[client_col] == client_id]
                client_total_apps = len(client_data)

                # Afficher le nom de l'organisation au lieu de l'ID
                client_name = org_map.get(client_id, str(client_id))

                print(f'\n   üìä Organisation: {client_name:<40} | Candidatures: {client_total_apps}')
                print(f'   {"‚îÄ" * 98}')

                # Statut pour ce client
                if 'status' in client_data.columns:
                    status_dist = client_data['status'].value_counts()
                    print(f'   Statuts: {", ".join([f"{s}:{c}" for s, c in status_dist.items()])}')

                # Campagnes pour ce client
                if job_col:
                    campaigns_for_client = client_data[job_col].value_counts()
                    print(f'   Campagnes: {len(campaigns_for_client)} uniques')
                    for campaign_id, count in campaigns_for_client.head(3).items():
                        print(f'      - {str(campaign_id):<45} : {count} candidatures')
                    if len(campaigns_for_client) > 3:
                        print(f'      ... et {len(campaigns_for_client) - 3} autres')

        # Liste compl√®te des offres/campagnes (r√©capitulatif)
        print(f'\nüíº R√©capitulatif des Campagnes / Offres')
        print('‚îÄ' * 100)
        if job_col:
            job_counts = booth_sessions[job_col].value_counts()
            num_campaigns = len(job_counts)
            print(f'   {"Rang":<6} {"Campagne / Offre (Job)":<60} {"Candidatures":>15}')
            print('   ' + '‚îÄ' * 92)
            for idx, (job_id, count) in enumerate(job_counts.items(), 1):
                job_title = job_map.get(job_id, str(job_id))[:58]
                print(f'   {idx:<6} {job_title:<60} {count:>15}')
            print('   ' + '‚îÄ' * 92)
            print(f'   Total: {len(job_counts)} campagnes uniques')
        else:
            print(f'   ‚ÑπÔ∏è Donn√©es de campagnes non disponibles')

        # ===== ANALYSE D√âTAILL√âE PAR CAMPAGNE =====
        print(f'\nüîç ANALYSE D√âTAILL√âE PAR CAMPAGNE')
        print('‚îÄ' * 100)
        if job_col:
            campaigns_list = booth_sessions[job_col].unique()
            for campaign_id in campaigns_list:
                campaign_data = booth_sessions[booth_sessions[job_col] == campaign_id]
                campaign_total_apps = len(campaign_data)

                # Afficher le titre de la campagne au lieu de l'ID
                campaign_title = job_map.get(campaign_id, str(campaign_id))

                print(f'\n   üìä Campagne: {campaign_title:<45} | Candidatures: {campaign_total_apps}')
                print(f'   {"‚îÄ" * 98}')

                # Statut pour cette campagne
                if 'status' in campaign_data.columns:
                    status_dist = campaign_data['status'].value_counts()
                    print(f'   Statuts: {", ".join([f"{s}:{c}" for s, c in status_dist.items()])}')

                # Clients pour cette campagne
                if client_col:
                    clients_for_campaign = campaign_data[client_col].value_counts()
                    print(f'   Clients: {len(clients_for_campaign)} uniques')
                    for client_id, count in clients_for_campaign.head(3).items():
                        print(f'      - {str(client_id):<45} : {count} candidatures')
                    if len(clients_for_campaign) > 3:
                        print(f'      ... et {len(clients_for_campaign) - 3} autres')

                # CV et autres stats
                cv_for_campaign = int(campaign_data['hasCvDownloaded'].sum()) if 'hasCvDownloaded' in campaign_data.columns else 0
                print(f'   CV cr√©√©s: {cv_for_campaign}')

        # Analyse par semaine
        print(f'\nüìÜ Analyse par Semaine')
        print('‚îÄ' * 100)
        if ANALYZE_PERIOD:
            if len(ANALYZE_PERIOD) == 7:
                filtered_sessions = booth_sessions[booth_sessions['year_month'].astype(str) == ANALYZE_PERIOD]
                print(f'   Filtre: Mois {ANALYZE_PERIOD}')
            elif len(ANALYZE_PERIOD) == 10:
                filtered_sessions = booth_sessions[booth_sessions['date'].astype(str) == ANALYZE_PERIOD]
                print(f'   Filtre: Jour {ANALYZE_PERIOD}')
            else:
                filtered_sessions = booth_sessions
        else:
            filtered_sessions = booth_sessions

        if len(filtered_sessions) > 0:
            print(f'   {"Semaine":<15} {"Candidatures":>15}')
            print('   ' + '‚îÄ' * 96)
            weekly_stats = filtered_sessions.groupby(['year', 'year_week']).agg({
                'applicationsCount': 'sum'
            }).reset_index()
            weekly_stats.columns = ['year', 'week', 'applications']
            weekly_stats = weekly_stats.sort_values('applications', ascending=False).head(10)

            for _, row in weekly_stats.iterrows():
                week_str = f"S{int(row['week']):02d}-{int(row['year'])}"
                apps = int(row['applications']) if row['applications'] > 0 else 0
                print(f'   {week_str:<15} {apps:>15}')
        else:
            print(f'   ‚ÑπÔ∏è Aucune donn√©e pour la p√©riode s√©lectionn√©e')

        # Stocker les donn√©es r√©capitulatives
        cabines_recap.append({
            'Cabine': booth_name,
            'Sessions': booth_total_sessions,
            'CV Cr√©√©s': booth_cv_created,
            'CV Imprim√©s': booth_cv_printed,
            'Candidatures': booth_apps,
            'Clients': num_clients,
            'Campagnes': num_campaigns,
            'Statuts': ', '.join([f'{k}:{v}' for k, v in status_recap.items()]) if status_recap else 'N/A'
        })

    # Afficher le tableau r√©capitulatif global
    print('\n\n' + '=' * 150)
    print('üìä TABLEAU R√âCAPITULATIF GLOBAL - TOUTES LES CABINES')
    print('=' * 150)

    if cabines_recap:
        # Cr√©er un DataFrame pour afficher le tableau
        recap_df = pd.DataFrame(cabines_recap)

        # Afficher le tableau format√©
        print('\n' + recap_df.to_string(index=False))

        print('\n' + '=' * 150)
        print(f'\nR√âSUM√â GLOBAL:')
        print('‚îÄ' * 150)
        print(f'   Nombre de cabines analys√©es: {len(cabines_recap)}')
        print(f'   Total sessions: {recap_df["Sessions"].sum()}')
        print(f'   Total CV cr√©√©s: {recap_df["CV Cr√©√©s"].sum()}')
        print(f'   Total CV imprim√©s: {recap_df["CV Imprim√©s"].sum()}')
        print(f'   Total candidatures: {recap_df["Candidatures"].sum()}')
        print(f'   Total clients uniques: {recap_df["Clients"].sum()}')
        print(f'   Total campagnes uniques: {recap_df["Campagnes"].sum()}')

else:
    print('‚ö†Ô∏è Pas de donn√©es de sessions disponibles pour l\'analyse par cabine')

# ============================================================
# üìÖ √âTAPE 5 : Timeline - √âvolution temporelle PAR CABINE
# ============================================================

# ============================================================
# üìÖ √âTAPE 13 : R√©sum√© final
# ============================================================

print('\n' + '=' * 100)
print('‚úÖ ANALYSE COMPL√àTE TERMIN√âE !')
print('=' * 100)
print(f'\nEnvironnement: {ENVIRONMENT}')
print(f'   {ENV_STATUS}')
print(f'   URL:   {API_URL}')
print(f'   P√©riode: {DATE_START} √† {DATE_END}')

print(f'\nüìä R√âSUM√â DES STATISTIQUES:')
print('‚îÄ' * 60)
print(f'   üîµ CV cr√©√©s: {total_cv_created}')
print(f'   üü¢ CV imprim√©s: {total_cv_printed}')
print(f'   üü° Offres consult√©es: {total_job_offers_viewed}')
print(f'   üü† Candidatures: {total_applications}')
print(f'   üî¥ Sessions: {total_sessions}')
print(f'   üü£ Utilisateurs ayant compl√©t√© une session: {total_users_completed_session}')

if total_cv_created > 0 or total_sessions > 0 or total_job_offers_viewed > 0:
    print(f'\nüìà INDICATEURS DE PERFORMANCE:')
    print('‚îÄ' * 60)
    if total_cv_created > 0 and total_cv_printed > 0:
        print(f'   ‚úì Taux d\'impression: {(total_cv_printed/total_cv_created)*100:.1f}%')
    if total_cv_created > 0 and total_job_offers_viewed > 0:
        print(f'   ‚úì Ratio offres/CV: {(total_job_offers_viewed/total_cv_created):.2f}')
    if total_cv_created > 0 and total_applications > 0:
        print(f'   ‚úì Ratio candidatures/CV: {(total_applications/total_cv_created):.2f}')
    if total_sessions > 0 and total_cv_created > 0:
        print(f'   ‚úì CV par session: {(total_cv_created/total_sessions):.2f}')
    if total_sessions > 0 and total_users_completed_session > 0:
        print(f'   ‚úì Taux de compl√©tion: {(total_users_completed_session/total_sessions)*100:.1f}%')

print(f'\nConfiguration active:')
print(f'   Cabines: {CABINES_TO_ANALYZE}')
print(f'   P√©riode d√©tails: {ANALYZE_PERIOD if ANALYZE_PERIOD else "Toutes"}')
print(f'   Export Excel: D√©sactiv√©')
print('\n' + '=' * 100)

